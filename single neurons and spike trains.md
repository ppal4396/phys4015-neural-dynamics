# single neurons and spike trains

## membrane potential

**membrane potential**: neurons have a potential difference across their cell membranes, due to concentration differences in ions that are maintained by ATP pumps (**ion pumps**).

**ion channels** allow particular ions through.

**Nernst potential**: the membrane potential at which the flow of a particular ion through open membrane channels due to a concentration gradient is nullified (by an electrical gradient in the opposite direction). Given by:
$$E_A = \frac{k_B T} {z_A q_e} \ln \frac{[A_{out}]}{[A_{in}]} $$
- $T$ is temperature, converted to units of thermal energy by Boltzmann constant $k_B$
- $z_A$ is charge (discrete) of the ion, converted to continuous electronic charge by fundamental charge of an electron $q_e$
- $A$ is the ion, subscript indicates inside or outside cell.

The force due to electrical gradient is much stronger than concentration gradient (as the electrical gradient increases, chance of an ion moving against it exponentially decreases).

Movement of ions through channels try to push the membrane potential towards their Nernst potential. However the membrane potential is continually reset by ion pumps; which create the concentration gradients and the existence of the Nernst potential in the first place.

Membrane is said to be 'polarised' because of the excess negative and positive charges building up on the inside and outside respectively.

Opening ion channels leading to positive charge flowing in is called 'depolarisation' since the imbalance in charge is reduced.

Further removal of positive charge from the cell is called 'hyperpolarisation' since imbalance in charge is increased.

## circuit model of neuronal membrane

![[circuit model of neuronal membrane.png|300]]
- capacitor represents membrane surface's ability to store charge (ions sort of build up against lipid bilayer)
- some gated ion channels are represented in parallel; each channel is a battery + resistor.
	- an effective battery is produced by high concentration gradient
	- resistor is produced by the conductance of the channel.
	- conductance is variable since the channels are gated (except for the 'leak channel')
- leaky channel at the end represents the ion pumps that charge the capacitor i.e. bring the membrane to resting potential.
- the vertical arrows are directed to show current flow when membrane potential is at 0 mV 
	- (i.e. 0 mV is above resting potential, above Nernst potential for K, and below Nernst potentials for Na, Ca)

The resting membrane potential is given when the net current through each of the channels is zero.
$$I_m = \sum_{A} G_A (V_m - E_A) = 0$$
- We're summing the current through each ion channel $A$ here.
- $G_A$ is the channel's conductance, $E_A$ is its Nernst potential

The resting membrane potential (in the above circuit where we have Na, Ca and K channels) is given by

$$V_m = 
\frac
{G_{Na}E_{Na} + G_{Ca}E_{Ca} + G_{K}E_{K} + G_{L}E_{L}}
{G_{Na} + G_{Ca} + G_{K} + G_{L}}$$

A model for the membrane potential's *dynamics* can be quickly derived as follows. First consider all conductances as fixed and only use the leaky channel term to model current through the membrane.
$$I_m = G_L(V_m - E_L)$$
Since membrane potential is generated by charge $Q$ stored on the membrane (i.e. in the capacitor above) it can be modelled in relation to capacitance $C_m$.
$$Q = C_m V_m$$
Rate of change in charge is given by current through the membrane.
$$\frac{dQ}{dt} = - I_m = - G_L(V_m - E_L)$$
Since capacitance is fixed over time, changing membrane potential is modelled inside (combine above two equations):

$$C_m \frac{dV_m}{dt} 
= G_L (E_L - V_m)$$

Solving this to get $V_m$ as a function of time gives

$$V_m(t) = E_L +
\left [ V_0 - E_L \right ]
\exp{(- t / \tau_m)}$$

Therefore membrane potential dynamics follow an exponential decay function, towards steady state value $E_L$. 
- Time constant $\tau_m = C_m / G_L$ 
- $V_0$ is the initial potential

The steady state value $E_L$ is typically around $-60$ to $-75$ mV. Note negative value indicates negative potential inside the cell relative to outside. 

## Hodgkin-Huxley model of conductance-based dynamics

> [!note]
> Described in Ch 4. Miller

Describes cell membrane potential as continuous dynamic system. Captures the feedback loop between membrane potential and channel conductance; modelling the appearance of single neuronal dynamics such as spikes, sub-spike-threshold oscillations, resonance  (periodic activity) and bistability (spiking vs quiet state).

Components:
- cell membrane (capacitor)
- Voltage-gated Ion channels (nonlinear conductance)
- Leaky ion channels (linear conductance)
- Electrochemical gradients driving flows of ions (voltage sources)
- Ion exchangers (current sources)

Total current through membrane is conceptualised as above; the sum of current through each channel, with the addition of experimentally applied current
$$I_m = C_m \frac{dV_m}{dt} = \sum_A G_A (V_m - E_A) + I _{app}$$
But Hodgkin-Huxley introduces gating variables for the degree of activation of voltage-gated sodium and potassium channels.
-  $m$ (sodium activation variable)
- $h$ (sodium inactivation variable)
- $n$ (potassium inactivation variable).

Each gating variable has a voltage-dependent steady state value (would reach this value if membrane potential was fixed) and a voltage-dependent time constant (for how long it takes to reach its steady state).

Four coupled differential equations are used to describe varying cell membrane potential. The exponents were derived via voltage-clamped experiments in squid axons.

1. 

$$C_m \frac {dV_m} {dt} = 
  \bar{G}_K n^4 (V_m - E_K) + 
  \bar{G}_{Na} m^3 h ( V_m - E_{Na} ) + 
  \bar{G}_L \cdot (V_m - E_L) +
  I_{app}$$
  
2. $$\frac {dn} {dt} = \alpha_n (1 - n) - \beta_n n$$
3. $$\frac{dm}{dt} = \alpha_m (1 - m) - \beta_m m$$
4. $$\frac{dh}{dt}= \alpha_h (1 - h) - \beta_h h$$
where
- $\bar{G}$ is maximal conductance
- $n$ is a dimensionless probability in $[0, 1]$ of $K$ channel subunit activation
	- (in theory raised to 4th power because four subunits that require activation, but this was originally found empirically)
-  $m$ is a dimensionless probability in $[0, 1]$ of $Na$ channel subunit activation
- $h$ is a dimensionless probability in $[0, 1]$ of $Na$ channel subunit inactivation.
- $\alpha$ is a rate constant, dependent on membrane potential. (since steady state values depend on $V_m$)
$$\alpha = \text{steady state value for activation}  / \tau$$
- $\beta$ is a rate constant, dependent on membrane potential.  
$$\beta = \text{steady state value for inactivation} / \tau$$
Note $\tau$ is a time constant for the relevant gating variable ($n$, $m$ or $h$).
Steady state values can be modelled differently (but always depends on $V_m$).

When the voltage-dependence of rate constants are known, the gating variables and dynamics in membrane potential can be simulated in response to external current.

## leaky integrate-and-fire model of spike events

> [!note]
> Described in Ch. 2.3 Miller

A simpler alternative to producing spiking behaviour of single neurons (biophysics of voltage-gated channels are ignored). Membrane potential has a capacitance and leak term only; and is reset when it reaches spiking threshold.

Following simplification of the circuit model (where ion-channel conductances are fixed/ignored), we model current through the membrane using leaky channel term plus externally applied current.

$$I_m = C_m \frac{dV_m}{dt} = 
G_L (E_L -V_m) + I_{app} \ ;
\text{if } V_m > V_{thresh} \ \text{then }
V_m \mapsto V_{reset}$$

Without the leaky conductance term, membrane potential would perfectly integrate the external current applied. Leaky conductance term leads to exponential decay.

The steady state value for $V_m$ is found when $dV_m/dt = 0$:
$$V_{ss} = \frac {I_{app}} {G_L} + E_L$$
When $I_{app}$ is high enough, $V_{ss}$ reaches $V_{thresh}$. That is, this is the current needed to generate spikes and can be written as $I_{thresh}$, substituted into the above:
$$I_{thresh} = G_L(V_{thresh} - E_L)$$

### derivation of regular spike times in LIF under constant driving current
$$\tau_m \frac{du}{dt} = - u(t) + RI(t)$$
where
- $\tau_m$ = membrane time constant
- $u$ = membrane potential
- $R$ = membrane resistance
- $I$ = driving current through membrane

Spikes are characterised by their firing time 

$$t^{(f)} : u(t^{(f)}) = u_{th}$$

where $u_{th}$ is a firing threshold.
Immediately after $t^{(f)}$, the potential is reset, following

$$\lim_{t \to t^{(f)} \space ; \space t > t^{(f)}} 
u(t) = u_r$$

where $u_r$ is the resting potential.

Suppose a spike occurs at $t = t^{(1)}$, where $I(t) = I_0$. The membrane potential at a time after $t^{(1)}$ is given by

$$u(t) = RI_0 \bigl( 1 - \exp ( - \frac{t - t^{(1)}} {\tau_m}) \bigr) $$
From the above, we have a spike at a point in time, if $RI_0 > u_{th}$, and no spike otherwise.

We can find the time taken $T= t^{(2)} - t^{(1)}$ for the membrane potential to reset, and another spike to occur, as follows.

$$u_{th} = RI_0 \bigl( 1 - \exp ( - \frac{t^{(2)} - t^{(1)}} {\tau_m}) \bigr)$$
$$T = \tau_m \ln\frac{RI_0}{RI_0 - u_{th}}$$
This shows the regular spike pattern/oscillatory activity generated by the LIF model, with constant driving current.

## analysing individual spike trains

> [!note]
> Described in Ch. 3 Miller

**Observed spike trains are stochastic**

- without external stimulus, spike trains show high variability/irregularity
- with external constant stimulus, there is still variability in resulting spike train
- across trials, the same stimulus can lead to varying spike times and total number of spikes

### poisson point process

> [!note]
> Described in Ch. 3.3.3 Miller

Used to model individual spike trains. 

Poisson point process is a probabilistic production of events (discrete points in continuous time), like spikes, that have equal probability of occurring per unit time. In other words, it models a stochastic time series.

However note real neural spike trains often show greater variability than expected from a Poisson point process.

Can use variations on the Poisson point process to generate spike trains for each hypothesis and first test whether certain analyses are capable of distinguishing each hypothesis.

The Poisson point process depends on one parameter $r$ (the rate of events in a small time interval $\delta t$)
$$\text{probability of event in a time interval} = r \delta t$$
- $r$ in our context is interpreted as a firing rate

In a **homogenous Poisson point process** $r$ is fixed across time.

A **Poisson distribution** is the probability of a given number of events $N$ occurring in a time interval $T$ when the events are generated by a Poisson point process.

$$ P_T[N]: \text{probability that $n$ spikes occur in time interval $T$}$$
This ends up depending on one parameter $\lambda = rT$ as follows.
$$P_T[N] = \frac{\lambda^N}{N!}e^{-\lambda} $$
- $\lambda$ is also the expected value of the number of spikes in time interval $T$

We can arrive at the definition of Poisson point process from the distribution as follows:
$$P_{\delta t}[1] = \frac{{r \delta t}^1}{1!} e ^{-r\delta t}$$
$$P_{\delta t}[1] = {r \delta t}$$
- since $r \cdot \delta t << 1$  

A Poisson point process is *simulated* easily by choosing $\Delta t << 1/r$ to ensure the probability of more than one event occurring in the time interval is negligible.  Then generate the occurrence of a spike (or not) in each time bin.

#### derivation of the poisson distribution

> [!note]
> Described in Ch. 3.7.1 Miller

Start with the definition for a Poisson point process, where the probability of an event in a very small time interval is given by $r \delta t$. These events are independent.

$P_T[0]$ would be the product of independent probabilities $(1 - r\delta t)$ for each time interval $\delta t$.

Consider the probability of an event in exactly one particular interval $\delta t$ and no other intervals. Compared to $P_T[0]$, one factor $(1 - r \delta t)$ is replaced by $(r \delta t)$ and so is given by:
$$P_T[0] \cdot \frac {r \delta t}{1 - r \delta t}$$
If there are $N_T$ small time intervals in $T$, $P_T[1]$ is given by summing the $N_T$ ways of generating one such spike.
$$P_T[1] = N_T \cdot P_T[0] \cdot \frac{r \delta t}{1 - r \delta t}$$
Next, since
- $T = \delta t \cdot N_T$
- $1 - r \delta t \approx 1$ (since time interval is assumed to be so small that $r\delta t << 1$)
we have
$$P_T[1] = P_T[0] \cdot rT$$
Comparing any $P_T[N]$ to $P_T[N-1]$ is a difference in factor of
$$\frac{(N_T - N + 1)\cdot r \delta t}{N}$$
since 
- there are $N_T - N + 1$ intervals for the new spike to occur in for each arrangement from $P[N - 1]$
- and we divide by $N$ to avoid over counting, since each arrangement from $P[N-1]$ plus the new spike leads to a new arrangement that would otherwise appear $N$ times in the total count.

> [!hint] 
 > This makes sense if you draw the possible arrangements in a process for $P[1]$ and compare to $P[2]$

We therefore have for $N>0$
$$P_T[N] = \frac{N_T - N + 1}{N} \cdot r \delta t \cdot P_T[N-1]$$
Next, since
- $N + 1 << N_T$ (true when $\delta t \mapsto 0$ since we assume this means $r\delta t << 1$ and this implies most time bins are empty)
we have
$$P_T[N] = \frac{rT}{N} P_T[N-1]$$
Therefore, iterating up from $P_T[0]$ we can see $P_T[N]$ is given by
$$P_T[N] = \frac{(rT)^N}{N!} P_T[0]$$
Our next goal is to find $P_T[0]$.

Consider that
$$\sum _{N=0} ^{\infty} P_T[N] = 1$$
i.e., the chance that some non-negative number of spikes occurs in $T$ is certain by our definition. Integrating the Poisson distribution between 0 and infinity should of course yield 1.

We have

$$\sum _{N=0} ^{\infty} P_T[N] = P_T[0]\sum_{N=0}^{\infty}\frac{(rT)^N}{N!} = 1$$

Next, since exponential function $e^x$ is defined by
$$e^x = \sum_{N=0} ^{\infty} \frac{x^N}{N!}$$
We have
$$P_T[0] = e^{-rt}$$
Poisson distribution is therefore given by
$$P_T[N] = \frac{(rT)^N}{N!} e^{-rT} $$

### fano factor

Measures variability of spike times. 
Ratio of variance to mean (of the number of spikes within a given time window).

For varying time window lengths, fano factor of poisson model is 1; however in experimental data, fano factor can increase to 100 for a window of 100 seconds. So for longer time windows, variability of spike times increases beyond a Poisson model of stochasticity. 

Similar observation: in cortical neurons, counting number of spikes in varying interval lengths, we observe a long right-tailed distribution. i.e. spike count rate increases in longer time windows.

### inter-spike interval

the intervals between consecutive spike events.
$$T_i = t_{i+1} - t_i$$

**Co-efficient of Variation** of ISIs also measures variability of spike times:
the standard deviation divided by the mean
$$C_V=\frac{(Var(T_i))^{1/2}}{\langle T_i \rangle}$$
$C_V$ is 1 for Poisson process (and histogram of ISIs is shaped like exponential decay).

$C_V$ is close to zero for a regular set of spikes.

Experimentally, ISIs fall in right-skewed distributions.

#### derivation of CV of ISIs for poisson point process

> [!note]
> Described in Ch. 3.7.4 Miller

### tuning curve

a plot of a neuron's changing firing rate in response to a range of stimuli (or some changing parameter in a stimulus e.g. spatial location of visual stimulus, pitch of auditory stimulus, frequency of vibrational stimulus).

### neural response function

Simple way to calculate total response to a stimulus. 

We have a set of spike times, after some stimulus. 
$$S = \{t_1, t_2, \ldots , t_n \}$$
Total **neural response** in a time interval can then be represented by summing times since previous spikes. $\delta$ is dirac delta function (?) 
$$\rho (t) = \sum_{i=1}^{n}\delta(t - t_i)$$
### spike count rate

**spike-count rate** counts the number of spikes in a time interval, divided by time interval. This is equivalent to average neural response?
$$r = \frac{n}{T} = \frac{1}{T}\int_0^{T}\rho(\tau)\,d\tau$$
### firing rate (or 'spike density')

Choose a time bin width. Count the number of spikes in each time bin, averaged across all trials for this neuron. Divide each count by width of time bin. Now you have firing rate as a function of time.

**firing rate (averaged across trials)** 
$$r(t)=\frac{1}{\triangle t}\int_t^{t+\triangle t}\langle \rho(\tau)\rangle \, d\tau$$
### average firing rate (or 'population activity')

This is the firing rate, but, in each time bin (or, as written below, for one time window), you find average spike count across population, instead of across trials.

 **firing rate (averaged across population)**
$$\langle r \rangle= \frac{\langle n \rangle}{T} = \frac{1}{T}\int_0^{T}\langle\rho(\tau)\rangle\,d\tau = \frac{1}{T}\int_0^Tr(\tau) \, d\tau$$
### reverse correlation

This is a spike triggered average (average number of stimuli per spike within some time window e.g. 100 ms).

Has been shown that spike triggered average can be used for stimulus reconstruction, indicating fundamentally that time-varying input to a single neuron is indeed encoded by its spike times.

This can also be used to estimate receptive fields.

### peristimulus time histogram (PSTH)

Estimates 'mean response' of a neuron to a stimulus

1. Align spike times across trials to stimulus onset.
2. Bin time into small windows.
3. Estimate mean firing rate as a function of time. See firing rate ('spike density') above.
	- Average the number of spikes in each window across trials.

Trade-off: larger bins leads to more accurate mean firing rate but with less sensitivity to time-variations in rate.

Alternative methods: 
- sliding windows
- replace each spike time with a Gaussian function centred on the spike time. The wider the Gaussian, the less noisy the resulting PSTH but with lower temporal resolution.

### ROC curve

ROC can be used to test whether a single neuron's response predicts with reliability the presence or absence of a stimulus.

> [!note]
> Described in Ch. 3.5.1, Miller. Leads into nice discussion of recollection vs familiarity
